# -*- coding: utf-8 -*-
"""Binary text classification Flask App.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l5cYHcNePQpGPdMMkR0TMVm3nNinzjYc
"""

from flask import Flask, render_template, request
from flask import Flask,render_template,url_for,request
import pandas as pd 
import numpy as np
import re
import pickle
import string
from nltk import pos_tag
from nltk.corpus import stopwords
from nltk.tokenize import WhitespaceTokenizer
from nltk.stem import WordNetLemmatizer
from nltk import word_tokenize
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation
from keras.layers.embeddings import Embedding
import os

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import LSTM

from keras.layers import Bidirectional
from keras.preprocessing import sequence
from keras.layers import Dropout
from keras.models import model_from_json
from keras.models import load_model
app = Flask(__name__)
import nltk
from nltk.stem import WordNetLemmatizer
import pickle
import numpy as np
from keras.models import load_model
from nltk.corpus import wordnet
import json
import random

def get_wordnet(pos_tag):
    if pos_tag.startswith('J'):
        return wordnet.ADJ
    elif pos_tag.startswith('V'):
        return wordnet.VERB
    elif pos_tag.startswith('N'):
        return wordnet.NOUN
    elif pos_tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

import nltk
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
def clean_rev(rev):
    # lower text
    rev = rev.lower()
    rev1=rev.split(" ")
    # tokenize text and remove puncutation
    rev = [word.strip(string.punctuation) for word in rev1]
    # remove words that contain numbers
    rev = [word for word in rev if not any(c.isdigit() for c in word)]
    # remove stop words
    stop_W = stopwords.words('english')
    rev = [word for word in rev if word not in stop_W]
    # remove empty tokens
    rev = [emp for emp in rev if len(emp) > 0]
    # pos tag text
    pos_tags = pos_tag(rev)
    # lemmatize text
    rev = [WordNetLemmatizer().lemmatize(tag[0], get_wordnet(tag[1])) for tag in pos_tags]
    # remove words with only one letter
    rev = [t for t in rev if len(t) >=1]
    # join all
    rev = " ".join(rev)
    return(rev)


app = Flask(__name__)
vocabulary_size = 20000
@app.route('/')
def home():
	return render_template('home.html')

@app.route('/Submit',methods=['POST'])
def predict():

  model = load_model('model.h5')

	#Alternative Usage of Saved Model
	# joblib.dump(clf, 'NB_spam_model.pkl')
	# NB_spam_model = open('NB_spam_model.pkl','rb')
	# clf = joblib.load(NB_spam_model)
  with open('tokenizer.pickle', 'rb') as handle:
      tokenizer = pickle.load(handle)
   
  if request.method == 'POST':
    message = request.form['message']
    #data = [message]
    #vect = clean_rev(message)
    # loading
    message=clean_rev(message)
 
 
    #tokenizer.fit_on_texts([message])
    sequences = tokenizer.texts_to_sequences([message])
    #maxSize = max(len(seq) for seq in sequences)
    input_msg = pad_sequences(sequences, maxlen=20000)
    #my_prediction = model.predict(np.array(input_msg))[0]
    my_prediction = int(model.predict(input_msg).round().item())
  return render_template('result.html',prediction = my_prediction)

if __name__ == '__main__':
  app.run(host="127.0.0.1", port=int("5008"),debug=True)

